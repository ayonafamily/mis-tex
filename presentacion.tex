\documentclass[aspectratio=169]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath,amssymb,graphicx,enumitem,xurl,hyperref}
% Definir un verde más oscuro (puedes ajustar los valores)

\usepackage{xcolor}
\definecolor{verdeIA}{RGB}{76,200,88}
\hypersetup{colorlinks=true, urlcolor=verdeIA}

\usetheme{Madrid}
\usecolortheme[named=verdeIA]{structure}


\title{Análisis de ``Antiqua et Nova''\\Inteligencia artificial y ética}
\author{Jorge L. Ayona Inglis}
\date{\today}

\begin{document}

\frame{\titlepage}

\begin{frame}{Resumen de los núms. 100 y 101}
\begin{itemize}
  \item El n. 100 denuncia el desarrollo de armas autónomas que actúan sin intervención humana.
  \item Se plantea un problema ético y jurídico respecto a la responsabilidad moral.
  \item El n. 101 advierte que la IA puede convertirse en un riesgo existencial.
  \item Llamado a examinar la guerra con una mentalidad nueva (\textit{Gaudium et spes}).
\end{itemize}
\end{frame}

\begin{frame}{Modelo de Toulmin del n. 100}
\begin{itemize}
  \item \textbf{Afirmación:} Las armas autónomas deben ser cuestionadas éticamente.
  \item \textbf{Fundamento:} Eluden la responsabilidad humana.
  \item \textbf{Garantía:} Quitar la vida requiere juicio moral humano.
  \item \textbf{Respaldo:} Apoyo en la enseñanza social de la Iglesia y el derecho internacional.
  \item \textbf{Reserva:} Aunque puedan reducir errores, no justifican eliminar el juicio ético.
  \item \textbf{Modalizador:} \textit{Es altamente cuestionable...}
\end{itemize}
\end{frame}

\begin{frame}{Modalizador}
\textit{Es altamente cuestionable, desde una perspectiva ética y jurídica, permitir que algoritmos tomen decisiones irreversibles sobre vidas humanas sin supervisión responsable.}

\vspace{1em}
Indica:
\begin{itemize}
  \item Certeza razonada, no absoluta.
  \item Compromiso ético.
  \item Invitación a la reflexión seria sobre los límites morales del uso de IA en armamento.
\end{itemize}
\end{frame}

\begin{frame}{Conclusión}
\begin{itemize}
  \item Delegar decisiones letales a máquinas es moralmente inaceptable.
  \item Se pierde la responsabilidad moral directa del ser humano.
  \item No basta con reducir errores: se requiere conciencia y juicio.
  \item La comunidad internacional debe establecer límites éticos y legales.
  \item Necesitamos una cultura de paz basada en la dignidad humana.
\end{itemize}
\end{frame}

\begin{frame}{Caso ilustrativo: RoboCop (1987)}
\begin{itemize}
  \item El robot ED-209 mata a un ejecutivo por error.
  \item Actúa sin discernimiento, incluso tras cesar la amenaza.
  \item La escena ilustra peligros reales de IA autónoma sin control humano.
  \item Conecta con la advertencia de \textit{Antiqua et Nova} sobre el "riesgo existencial".
\end{itemize}
\end{frame}

\begin{frame}{Escena recomendada}
\textbf{Video:} \href{https://www.youtube.com/watch?v=TYsulVXpgYg}{RoboCop (1987) -- ED-209 malfunction scene}

\includegraphics[width=0.9\linewidth]{robocop.png}
\end{frame}

\end{document}
